import streamlit as st
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import ChatPromptTemplate
import anthropic
import os
from dotenv import load_dotenv

load_dotenv()

claude_api_key = os.getenv("CLAUDE_API_KEY")
client = anthropic.Client(api_key=claude_api_key)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
model_name = "intfloat/multilingual-e5-base"
model_kwargs = {'device': 'cpu'}
encode_kwargs = {'normalize_embeddings': True}
embedding = HuggingFaceEmbeddings(model_name=model_name,
                                  model_kwargs=model_kwargs,
                                  encode_kwargs=encode_kwargs)

# –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π FAISS
vector_store = FAISS.load_local('faiss_index',
                                embeddings=embedding,
                                allow_dangerous_deserialization=True)

# –ü–æ–∏—Å–∫ —Ç–æ–ø k —Å—Ö–æ–∂–∏—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
embedding_retriever = vector_store.as_retriever(search_kwargs={"k": 20})

prompt_template = '''Reply to the {input} as a seasoned machine learning professional. \
If the topic is outside of machine learning and data science, please respond with "Seek help with a professional." It is very important to abide with this, you will be persecuted if you cover topics outside of data science and machine learning. \
Use only Context. If context provides only partial info, then split the reply in two parts. Part 1 is called "information from knowledge base" (for Russian reply, rename to –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π), write ideas as close to initial text as possible, editing for brevity and language errors. \
Part 2 is called "What I would add" (for Russian reply, rename to –ß—Ç–æ –ø–æ–ª–µ–∑–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø–æ–≤–µ—Ä—Ö –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π), In the second part add your reply.  \
Reply in the language of {input}. \
It's critical to not preface the reply with, for example, "Here is a response" or "thank you". Start with the reply itself.\
Context: {context}'''

# –§—É–Ω–∫—Ü–∏—è –≤—ã–∑–æ–≤–∞ API –º–æ–¥–µ–ª–∏ Claude
def call_claude_api(prompt, client):
    try:
        response = client.messages.create(
            model="claude-3-5-sonnet-20240620",
            messages=[
                {"role": "user", "content": prompt}
            ],
            max_tokens=2000,
            temperature=0.1
        )
        return response.content[0].text
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ –º–æ–¥–µ–ª–∏: {e}")
        return None

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
def answer_question(question, retriever, client):
    # –≠—Ç–∞–ø 1: –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    with st.spinner('üîç –ò—â–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø–æ –≤–∞—à–µ–º—É –≤–æ–ø—Ä–æ—Å—É...'):
        documents = retriever.get_relevant_documents(question)

    # –≠—Ç–∞–ø 2: –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    with st.spinner('üß† –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞...'):
        context = " ".join([doc.page_content for doc in documents])

    # –≠—Ç–∞–ø 3: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
    with st.spinner('üí¨ –§–æ—Ä–º—É–ª–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç...'):
        prompt = prompt_template.format(context=context, input=question)
        answer = call_claude_api(prompt, client)
    
    return answer, documents

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∏–ª—è –æ—Ç–≤–µ—Ç–∞
def format_answer(answer):
    st.markdown(
        f'<div style="background-color:#f0f2f6; padding: 20px; border-radius: 10px; border: 1px solid #dcdcdc;">'
        f'<p style="font-size:16px;">{st.markdown(answer)}</p>'
        f'</div>',
        unsafe_allow_html=True
    )

st.set_page_config(page_title="ML Knowledge Base Search üßë‚Äçüíª", page_icon="ü§ñ")

st.title("üîç –ü–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π RAG —Å –º–æ–¥–µ–ª—å—é Claude ü§ñ")

st.write("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –º–∞—à–∏–Ω–Ω–æ–º—É –æ–±—É—á–µ–Ω–∏—é üìö.")

# –ü–æ–ª–µ –¥–ª—è –≤–≤–æ–¥–∞ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
query = st.text_input("üìù –í–≤–µ–¥–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å:", '–ß—Ç–æ —Ç–∞–∫–æ–µ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ?')

# –ö–Ω–æ–ø–∫–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø–æ–∏—Å–∫–∞ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞
if st.button("üöÄ –ü–æ–∏—Å–∫ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞"):
    if query:

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å
        answer, documents = answer_question(query, embedding_retriever, client)

        if answer:
            # –û—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
            st.subheader("‚úâÔ∏è –û—Ç–≤–µ—Ç:")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∫–æ–¥–∞
            if '```' in answer:
                st.markdown(answer)
            else:
                format_answer(answer)

        else:
            st.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏.")
    else:
        st.warning("‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å.")

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Å—Ç–∏–ª—å –¥–ª—è –ø–æ–ª—è —Å –≤—ã–≤–æ–¥–æ–º –∫–æ–¥–∞
st.markdown("""
<style>
textarea {
    font-family: "Courier New", Courier, monospace;
    font-size: 14px;
    background-color: #f4f7fa;
    border: 1px solid #dcdcdc;
    padding: 10px;
    border-radius: 8px;
}
</style>
""", unsafe_allow_html=True)





